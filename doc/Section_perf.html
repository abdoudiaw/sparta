<HTML>
<CENTER><A HREF = "Section_example.html">Previous Section</A> - <A HREF = "http://sparta.sandia.gov">SPARTA WWW Site</A> - <A HREF = "Manual.html">SPARTA Documentation</A> - <A HREF = "Section_commands.html#comm">SPARTA Commands</A> - <A HREF = "Section_tools.html">Next Section</A> 
</CENTER>






<HR>

<H3>8. Performance & scalability 
</H3>
<P>The SPARTA distribution includes a bench sub-directory with several
sample problems.  The benchmark data on the Benchmarks page of the
<A HREF = "http://sparta.sandia.gov">SPARTA WWW Site</A> gives timing data for these problems being run
on different machines.
</P>
<P>TODO: put final list here
</P>
<OL><LI>Free = free molecular flow in a box 

<LI>Collide = collisional molecular flow in a box 

<LI>Sphere = flow around a sphere 
</OL>
<P>For each problem there is an input script and sample log file outputs
on different machines and different numbers of processors.  E.g. a log
file like log.free.foo.P means it ran on P processors of machine
"foo".
</P>
<P>Each can be run as a serial benchmark (on one processor) or in
parallel.  In parallel, all the benchmarks can be run as a fixed-size
problem, meaning the same problem is run on various numbers of
processors.  Some can be run as scaled-size problem, if the problem
size is increased with the number of processors.
</P>
<P>Here is how to run each of the benchmarks:
</P>
<P>TODO: put full list here
</P>
<P>1-processor runs:
</P>
<PRE>spa_g++ -v x 100 -v y 100 -v z 100 < in.free
spa_g++ -v x 100 -v y 100 -v z 100 < in.collide
spa_g++ < in.sphere 
</PRE>
<P>32-processor runs:
</P>
<PRE>mpirun -np 32 spa_g++ -v x 100 -v y 100 -v z 100 < in.free
mpirun -np 32 -v x 100 -v y 100 -v z 100 < in.collide
mpirun -np 32 spa_g++ < in.sphere 
</PRE>
<P>Note that the free and collide benchmarks have variable settings that
determine the size of problem that is run.  These can be set from the
command line.  Each grid cell will have 10 particles, so that a run
with 1 million grid cells will have 10 million particles.
</P>
</HTML>
